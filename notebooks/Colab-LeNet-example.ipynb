{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "LeNet-example.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinhngx/TRTorch/blob/colab-lenet/notebooks/Colab-LeNet-example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwlMSB8EMMFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2019 NVIDIA Corporation. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZzvg5CzMMFT",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
        "\n",
        "# TRTorch LeNet Demo on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvjs1T4lMMFU",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In the practice of developing machine learning models, there are few tools as approachable as PyTorch for developing and experimenting in designing machine learning models. The power of PyTorch comes from its deep integration into Python, its flexibility and its approach to automatic differentiation and execution (eager execution). However, when moving from research into production, the requirements change and we may no longer want that deep Python integration and we want optimization to get the best performance we can on our deployment platform. In PyTorch 1.0, TorchScript was introduced as a method to separate your PyTorch model from Python, make it portable and optimizable. TorchScript uses PyTorch's JIT compiler to transform your normal PyTorch code which gets interpreted by the Python interpreter to an intermediate representation (IR) which can have optimizations run on it and at runtime can get interpreted by the PyTorch JIT interpreter. For PyTorch this has opened up a whole new world of possibilities, including deployment in other languages like C++. It also introduces a structured graph based format that we can use to do down to the kernel level optimization of models for inference.\n",
        "\n",
        "When deploying on NVIDIA GPUs TensorRT, NVIDIA's Deep Learning Optimization SDK and Runtime is able to take models from any major framework and specifically tune them to perform better on specific target hardware in the NVIDIA family be it an A100, TITAN V, Jetson Xavier or NVIDIA's Deep Learning Accelerator. TensorRT performs a couple sets of optimizations to achieve this. TensorRT fuses layers and tensors in the model graph, it then uses a large kernel library to select implementations that perform best on the target GPU. TensorRT also has strong support for reduced operating precision execution which allows users to leverage the Tensor Cores on Volta and newer GPUs as well as reducing memory and computation footprints on device.\n",
        "\n",
        "TRTorch is a compiler that uses TensorRT to optimize TorchScript code, compiling standard TorchScript modules into ones that internally run with TensorRT optimizations. This enables you to continue to remain in the PyTorch ecosystem, using all the great features PyTorch has such as module composability, its flexible tensor implementation, data loaders and more. TRTorch is available to use with both PyTorch and LibTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO28OrdCMMFb",
        "colab_type": "text"
      },
      "source": [
        "### Learning objectives\n",
        "\n",
        "This notebook demonstrates the steps for compiling a TorchScript module with TRTorch on a simple LeNet network. \n",
        "\n",
        "## Content\n",
        "1. [Requirements](#1)\n",
        "1. [Creating TorchScript modules](#2)\n",
        "1. [Compiling with TRTorch](#3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP9fX-8rMMFf",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"1\"></a>\n",
        "## 1. Requirements\n",
        "First, we will install several required extra packages, then proceed to compile and install TRTorch from source.\n",
        "\n",
        "Make sure you choose GPU as the execution environment via `Runtime -> Change runtime type -> GPU`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2g08oW-NgEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "1a75ad7b-f4c1-4523-d9ff-d3ee5d1bd4c0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul  7 13:59:05 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   30C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txLlj6N_iCej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b43f5356-3176-4614-9384-d328efcbc8ba"
      },
      "source": [
        "! add-apt-repository -y ppa:graphics-drivers/ppa\n",
        "! apt update\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Fresh drivers from upstream, currently shipping Nvidia.\n",
            "\n",
            "## Current Status\n",
            "\n",
            "Current long-lived branch release: `nvidia-430` (430.40)\n",
            "Dropped support for Fermi series (https://nvidia.custhelp.com/app/answers/detail/a_id/4656)\n",
            "\n",
            "Old long-lived branch release: `nvidia-390` (390.129)\n",
            "\n",
            "For GF1xx GPUs use `nvidia-390` (390.129)\n",
            "For G8x, G9x and GT2xx GPUs use `nvidia-340` (340.107)\n",
            "For NV4x and G7x GPUs use `nvidia-304` (304.137) End-Of-Life!\n",
            "\n",
            "Support timeframes for Unix legacy GPU releases:\n",
            "https://nvidia.custhelp.com/app/answers/detail/a_id/3142\n",
            "\n",
            "## What we're working on right now:\n",
            "\n",
            "- Normal driver updates\n",
            "- Help Wanted: Mesa Updates for Intel/AMD users, ping us if you want to help do this work, we're shorthanded.\n",
            "\n",
            "## WARNINGS:\n",
            "\n",
            "This PPA is currently in testing, you should be experienced with packaging before you dive in here:\n",
            "\n",
            "Volunteers welcome!\n",
            "\n",
            "### How you can help:\n",
            "\n",
            "## Install PTS and benchmark your gear:\n",
            "\n",
            "    sudo apt-get install phoronix-test-suite\n",
            "\n",
            "Run the benchmark:\n",
            "\n",
            "    phoronix-test-suite default-benchmark openarena xonotic tesseract gputest unigine-valley\n",
            "\n",
            "and then say yes when it asks you to submit your results to openbechmarking.org. Then grab a cup of coffee, it takes a bit for the benchmarks to run. Depending on the version of Ubuntu you're using it might preferable for you to grabs PTS from upstream directly: http://www.phoronix-test-suite.com/?k=downloads\n",
            "\n",
            "## Share your results with the community:\n",
            "\n",
            "Post a link to your results (or any other feedback to): https://launchpad.net/~graphics-drivers-testers\n",
            "\n",
            "Remember to rerun and resubmit the benchmarks after driver upgrades, this will allow us to gather a bunch of data on performance that we can share with everybody.\n",
            "\n",
            "If you run into old documentation referring to other PPAs, you can help us by consolidating references to this PPA.\n",
            "\n",
            "If someone wants to go ahead and start prototyping on `software-properties-gtk` on what the GUI should look like, please start hacking!\n",
            "\n",
            "## Help us Help You!\n",
            "\n",
            "We use the donation funds to get the developers hardware to test and upload these drivers, please consider donating to the \"community\" slider on the donation page if you're loving this PPA:\n",
            "\n",
            "http://www.ubuntu.com/download/desktop/contribute\n",
            " More info: https://launchpad.net/~graphics-drivers/+archive/ubuntu/ppa\n",
            "Press [ENTER] to continue or Ctrl-c to cancel adding it.\n",
            "\n",
            "Hit:1 https://storage.googleapis.com/bazel-apt stable InRelease\n",
            "Ign:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "Hit:1 https://storage.googleapis.com/bazel-apt stable InRelease\n",
            "Ign:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "60 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "E: Unable to locate package nvidia-450\n",
            "E: Unable to locate package nvidia-450-dev\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lllyNQXkJBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "d62be00f-a4c7-44a1-f405-eab2626acdb4"
      },
      "source": [
        "!apt-get update && apt-get install build-dep build-essential\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://storage.googleapis.com/bazel-apt stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [1 InRelease gpgv 2,256 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 2,256 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:3 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 2,256 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "\r0% [1 InRelease gpgv 2,256 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 2,256 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 2,256 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers] [Waitin\r                                                                               \rHit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Waiting for headers] [Connec\r                                                                               \rHit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Connecting to ppa.launchpad.\r                                                                               \rHit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Release.gpg gpgv 564 B] [Waiting for headers] [Connecting to ppa.launchpad.\r                                                                               \r0% [Waiting for headers] [Connecting to ppa.launchpad.net (91.189.95.83)]\r0% [4 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "E: Unable to locate package build-dep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V4hK498iqEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "4507270b-d2a3-4951-f73e-2b15bc2f3a51"
      },
      "source": [
        "!sudo apt install nvidia-driver-440"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Some packages could not be installed. This may mean that you have\n",
            "requested an impossible situation or if you are using the unstable\n",
            "distribution that some required packages have not yet been created\n",
            "or been moved out of Incoming.\n",
            "The following information may help to resolve the situation:\n",
            "\n",
            "The following packages have unmet dependencies:\n",
            " nvidia-driver-440 : Depends: libnvidia-gl-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: nvidia-dkms-440 (<= 440.100-1)\n",
            "                     Depends: nvidia-dkms-440 (>= 440.100)\n",
            "                     Depends: nvidia-kernel-common-440 (<= 440.100-1) but it is not going to be installed\n",
            "                     Depends: nvidia-kernel-common-440 (>= 440.100) but it is not going to be installed\n",
            "                     Depends: nvidia-kernel-source-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: libnvidia-compute-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: nvidia-compute-utils-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: libnvidia-decode-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: libnvidia-encode-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: nvidia-utils-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: xserver-xorg-video-nvidia-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: libnvidia-cfg1-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: libnvidia-ifr1-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Depends: libnvidia-fbc1-440 (= 440.100-0ubuntu0.18.04.1) but it is not going to be installed\n",
            "                     Recommends: libnvidia-compute-440:i386 (= 440.100-0ubuntu0.18.04.1) but it is not installable\n",
            "                     Recommends: libnvidia-decode-440:i386 (= 440.100-0ubuntu0.18.04.1) but it is not installable\n",
            "                     Recommends: libnvidia-encode-440:i386 (= 440.100-0ubuntu0.18.04.1) but it is not installable\n",
            "                     Recommends: libnvidia-ifr1-440:i386 (= 440.100-0ubuntu0.18.04.1) but it is not installable\n",
            "                     Recommends: libnvidia-fbc1-440:i386 (= 440.100-0ubuntu0.18.04.1) but it is not installable\n",
            "                     Recommends: libnvidia-gl-440:i386 (= 440.100-0ubuntu0.18.04.1) but it is not installable\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "E: Unable to correct problems, you have held broken packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmZs1DWAj_KI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "e2607d2f-1722-41c8-a507-60ac64384968"
      },
      "source": [
        "!sudo apt-get install -f"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 60 not upgraded.\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWGRY8ZqVDpq",
        "colab_type": "text"
      },
      "source": [
        "### Install Bazel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKse-PcGMwa1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "345d1a88-300b-47bc-9aeb-0ecb149ba709"
      },
      "source": [
        "%%bash\n",
        "apt update && apt install curl gnupg\n",
        "curl https://bazel.build/bazel-release.pub.gpg | apt-key add -\n",
        "echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | tee /etc/apt/sources.list.d/bazel.list\n",
        "\n",
        "apt update && apt install bazel-3.2.0\n",
        "ln -s /usr/bin/bazel-3.2.0 /usr/bin/bazel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "65 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "curl is already the newest version (7.58.0-2ubuntu3.9).\n",
            "gnupg is already the newest version (2.2.4-1ubuntu1.2).\n",
            "gnupg set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 65 not upgraded.\n",
            "OK\n",
            "deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\n",
            "Get:1 https://storage.googleapis.com/bazel-apt stable InRelease [2,256 B]\n",
            "Ign:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:9 https://storage.googleapis.com/bazel-apt stable/jdk1.8 amd64 Packages [3,912 B]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Fetched 6,168 B in 2s (3,541 B/s)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "65 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  bash-completion\n",
            "The following NEW packages will be installed:\n",
            "  bazel-3.2.0\n",
            "0 upgraded, 1 newly installed, 0 to remove and 65 not upgraded.\n",
            "Need to get 43.0 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 https://storage.googleapis.com/bazel-apt stable/jdk1.8 amd64 bazel-3.2.0 amd64 3.2.0 [43.0 MB]\n",
            "Fetched 43.0 MB in 1s (41.2 MB/s)\n",
            "Selecting previously unselected package bazel-3.2.0.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 144491 files and directories currently installed.)\r\n",
            "Preparing to unpack .../bazel-3.2.0_3.2.0_amd64.deb ...\r\n",
            "Unpacking bazel-3.2.0 (3.2.0) ...\r\n",
            "Setting up bazel-3.2.0 (3.2.0) ...\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "\r100  3199  100  3199    0     0  35943      0 --:--:-- --:--:-- --:--:-- 35943\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "ln: failed to create symbolic link '/usr/bin/bazel': File exists\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVTpOcRjPcEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "5cd4b0ea-fd6b-4769-d4e8-b4d9f9545075"
      },
      "source": [
        "!bazel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting Bazel installation...\n",
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "                                                           [bazel release 3.2.0]\n",
            "Usage: bazel <command> <options> ...\n",
            "\n",
            "Available commands:\n",
            "  analyze-profile     Analyzes build profile data.\n",
            "  aquery              Analyzes the given targets and queries the action graph.\n",
            "  build               Builds the specified targets.\n",
            "  canonicalize-flags  Canonicalizes a list of bazel options.\n",
            "  clean               Removes output files and optionally stops the server.\n",
            "  coverage            Generates code coverage report for specified test targets.\n",
            "  cquery              Loads, analyzes, and queries the specified targets w/ configurations.\n",
            "  dump                Dumps the internal state of the bazel server process.\n",
            "  fetch               Fetches external repositories that are prerequisites to the targets.\n",
            "  help                Prints help for commands, or the index.\n",
            "  info                Displays runtime info about the bazel server.\n",
            "  license             Prints the license of this software.\n",
            "  mobile-install      Installs targets to mobile devices.\n",
            "  print_action        Prints the command line args for compiling a file.\n",
            "  query               Executes a dependency graph query.\n",
            "  run                 Runs the specified target.\n",
            "  shutdown            Stops the bazel server.\n",
            "  sync                Syncs all repositories specified in the workspace file\n",
            "  test                Builds and runs the specified test targets.\n",
            "  version             Prints version information for bazel.\n",
            "\n",
            "Getting more help:\n",
            "  bazel help <command>\n",
            "                   Prints help and options for <command>.\n",
            "  bazel help startup_options\n",
            "                   Options for the JVM hosting bazel.\n",
            "  bazel help target-syntax\n",
            "                   Explains the syntax for specifying targets.\n",
            "  bazel help info-keys\n",
            "                   Displays a list of keys used by the info command.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_GLtu9eVPhl",
        "colab_type": "text"
      },
      "source": [
        "### Install Cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK0CQz8tNz9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "90475611-f44e-4f52-ae18-5ad9c3416144"
      },
      "source": [
        "!lsb_release -a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.3 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufA59GLUSGNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "77734be2-363c-45a7-9fb0-606b6290865f"
      },
      "source": [
        "%%bash\n",
        "os=\"ubuntu1804\"\n",
        "cuda=\"10.2.89\"\n",
        "wget https://developer.download.nvidia.com/compute/cuda/repos/${os}/x86_64/cuda-repo-${os}_${cuda}-1_amd64.deb\n",
        "sudo dpkg --force-all -i cuda-repo-*.deb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Reading database ... 144495 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1804_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-repo-ubuntu1804 (10.2.89-1) over (10.2.89-1) ...\n",
            "Setting up cuda-repo-ubuntu1804 (10.2.89-1) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-07-07 12:39:38--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.2.89-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2936 (2.9K) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1804_10.2.89-1_amd64.deb.1’\n",
            "\n",
            "     0K ..                                                    100%  136M=0s\n",
            "\n",
            "2020-07-07 12:39:38 (136 MB/s) - ‘cuda-repo-ubuntu1804_10.2.89-1_amd64.deb.1’ saved [2936/2936]\n",
            "\n",
            "\n",
            "Configuration file '/etc/apt/sources.list.d/cuda.list'\n",
            " ==> File on system created by you or by a script.\n",
            " ==> File also in package provided by package maintainer.\n",
            " ==> Keeping old config file as default.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdE1m0oLTQ10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94b36a85-710f-4f32-b5c3-a81cdfa39354"
      },
      "source": [
        "!apt install cuda-10-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  cuda-command-line-tools-10-2 cuda-compiler-10-2 cuda-cudart-10-2\n",
            "  cuda-cudart-dev-10-2 cuda-cufft-10-2 cuda-cufft-dev-10-2 cuda-cuobjdump-10-2\n",
            "  cuda-cupti-10-2 cuda-cupti-dev-10-2 cuda-curand-10-2 cuda-curand-dev-10-2\n",
            "  cuda-cusolver-10-2 cuda-cusolver-dev-10-2 cuda-cusparse-10-2\n",
            "  cuda-cusparse-dev-10-2 cuda-demo-suite-10-2 cuda-documentation-10-2\n",
            "  cuda-driver-dev-10-2 cuda-gdb-10-2 cuda-libraries-10-2\n",
            "  cuda-libraries-dev-10-2 cuda-license-10-2 cuda-memcheck-10-2\n",
            "  cuda-misc-headers-10-2 cuda-npp-10-2 cuda-npp-dev-10-2 cuda-nsight-10-2\n",
            "  cuda-nsight-compute-10-2 cuda-nsight-systems-10-2 cuda-nvcc-10-2\n",
            "  cuda-nvdisasm-10-2 cuda-nvgraph-10-2 cuda-nvgraph-dev-10-2 cuda-nvjpeg-10-2\n",
            "  cuda-nvjpeg-dev-10-2 cuda-nvml-dev-10-2 cuda-nvprof-10-2 cuda-nvprune-10-2\n",
            "  cuda-nvrtc-10-2 cuda-nvrtc-dev-10-2 cuda-nvtx-10-2 cuda-nvvp-10-2\n",
            "  cuda-runtime-10-2 cuda-samples-10-2 cuda-sanitizer-api-10-2\n",
            "  cuda-toolkit-10-2 cuda-tools-10-2 cuda-visual-tools-10-2 libcublas-dev\n",
            "  libcublas10\n",
            "The following NEW packages will be installed:\n",
            "  cuda-10-2 cuda-command-line-tools-10-2 cuda-compiler-10-2 cuda-cudart-10-2\n",
            "  cuda-cudart-dev-10-2 cuda-cufft-10-2 cuda-cufft-dev-10-2 cuda-cuobjdump-10-2\n",
            "  cuda-cupti-10-2 cuda-cupti-dev-10-2 cuda-curand-10-2 cuda-curand-dev-10-2\n",
            "  cuda-cusolver-10-2 cuda-cusolver-dev-10-2 cuda-cusparse-10-2\n",
            "  cuda-cusparse-dev-10-2 cuda-demo-suite-10-2 cuda-documentation-10-2\n",
            "  cuda-driver-dev-10-2 cuda-gdb-10-2 cuda-libraries-10-2\n",
            "  cuda-libraries-dev-10-2 cuda-license-10-2 cuda-memcheck-10-2\n",
            "  cuda-misc-headers-10-2 cuda-npp-10-2 cuda-npp-dev-10-2 cuda-nsight-10-2\n",
            "  cuda-nsight-compute-10-2 cuda-nsight-systems-10-2 cuda-nvcc-10-2\n",
            "  cuda-nvdisasm-10-2 cuda-nvgraph-10-2 cuda-nvgraph-dev-10-2 cuda-nvjpeg-10-2\n",
            "  cuda-nvjpeg-dev-10-2 cuda-nvml-dev-10-2 cuda-nvprof-10-2 cuda-nvprune-10-2\n",
            "  cuda-nvrtc-10-2 cuda-nvrtc-dev-10-2 cuda-nvtx-10-2 cuda-nvvp-10-2\n",
            "  cuda-runtime-10-2 cuda-samples-10-2 cuda-sanitizer-api-10-2\n",
            "  cuda-toolkit-10-2 cuda-tools-10-2 cuda-visual-tools-10-2\n",
            "The following packages will be upgraded:\n",
            "  libcublas-dev libcublas10\n",
            "2 upgraded, 49 newly installed, 0 to remove and 63 not upgraded.\n",
            "Need to get 1,428 MB of archives.\n",
            "After this operation, 3,272 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-license-10-2 10.2.89-1 [16.4 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-misc-headers-10-2 10.2.89-1 [1,111 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvcc-10-2 10.2.89-1 [37.4 MB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cuobjdump-10-2 10.2.89-1 [88.5 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprune-10-2 10.2.89-1 [39.5 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-compiler-10-2 10.2.89-1 [2,530 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvdisasm-10-2 10.2.89-1 [22.2 MB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-gdb-10-2 10.2.89-1 [2,769 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprof-10-2 10.2.89-1 [1,651 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-sanitizer-api-10-2 10.2.89-1 [2,161 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-memcheck-10-2 10.2.89-1 [139 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-10-2 10.2.89-1 [111 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-driver-dev-10-2 10.2.89-1 [11.8 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-dev-10-2 10.2.89-1 [491 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-10-2 10.2.89-1 [8,169 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-dev-10-2 10.2.89-1 [2,197 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvtx-10-2 10.2.89-1 [38.9 kB]\n",
            "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-command-line-tools-10-2 10.2.89-1 [27.0 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-10-2 10.2.89-1 [2,582 B]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvvp-10-2 10.2.89-1 [2,532 B]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-10-2 10.2.89-1 [6,413 kB]\n",
            "Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-dev-10-2 10.2.89-1 [8,822 B]\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cusolver-10-2 10.2.89-1 [85.6 MB]\n",
            "Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cusolver-dev-10-2 10.2.89-1 [15.2 MB]\n",
            "Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas10 10.2.2.89-1 [42.2 MB]\n",
            "Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-dev 10.2.2.89-1 [42.3 MB]\n",
            "Get:27 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cufft-10-2 10.2.89-1 [87.8 MB]\n",
            "Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cufft-dev-10-2 10.2.89-1 [164 MB]\n",
            "Get:29 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-curand-10-2 10.2.89-1 [38.9 MB]\n",
            "Get:30 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-curand-dev-10-2 10.2.89-1 [39.1 MB]\n",
            "Get:31 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cusparse-10-2 10.2.89-1 [59.2 MB]\n",
            "Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cusparse-dev-10-2 10.2.89-1 [59.7 MB]\n",
            "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-npp-10-2 10.2.89-1 [56.7 MB]\n",
            "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-npp-dev-10-2 10.2.89-1 [57.6 MB]\n",
            "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvml-dev-10-2 10.2.89-1 [53.8 kB]\n",
            "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvjpeg-10-2 10.2.89-1 [1,274 kB]\n",
            "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvjpeg-dev-10-2 10.2.89-1 [1,213 kB]\n",
            "Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-compute-10-2 10.2.89-1 [3,712 B]\n",
            "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-systems-10-2 10.2.89-1 [3,130 B]\n",
            "Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvgraph-10-2 10.2.89-1 [44.5 MB]\n",
            "Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvgraph-dev-10-2 10.2.89-1 [35.2 MB]\n",
            "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-visual-tools-10-2 10.2.89-1 [389 MB]\n",
            "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-tools-10-2 10.2.89-1 [2,496 B]\n",
            "Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-samples-10-2 10.2.89-1 [65.6 MB]\n",
            "Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-documentation-10-2 10.2.89-1 [54.1 MB]\n",
            "Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-dev-10-2 10.2.89-1 [2,614 B]\n",
            "Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-10-2 10.2.89-1 [2,584 B]\n",
            "Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-10-2 10.2.89-1 [2,830 B]\n",
            "Get:49 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-runtime-10-2 10.2.89-1 [2,532 B]\n",
            "Get:50 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-demo-suite-10-2 10.2.89-1 [3,880 kB]\n",
            "Get:51 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-10-2 10.2.89-1 [2,558 B]\n",
            "Fetched 1,428 MB in 27s (52.4 MB/s)\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "Extracting templates from packages: 58%W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package cuda-license-10-2.\n",
            "(Reading database ... 144495 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-license-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-license-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-misc-headers-10-2.\n",
            "Preparing to unpack .../01-cuda-misc-headers-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-misc-headers-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvcc-10-2.\n",
            "Preparing to unpack .../02-cuda-nvcc-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvcc-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cuobjdump-10-2.\n",
            "Preparing to unpack .../03-cuda-cuobjdump-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cuobjdump-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvprune-10-2.\n",
            "Preparing to unpack .../04-cuda-nvprune-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvprune-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-compiler-10-2.\n",
            "Preparing to unpack .../05-cuda-compiler-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-compiler-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvdisasm-10-2.\n",
            "Preparing to unpack .../06-cuda-nvdisasm-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvdisasm-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-gdb-10-2.\n",
            "Preparing to unpack .../07-cuda-gdb-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-gdb-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvprof-10-2.\n",
            "Preparing to unpack .../08-cuda-nvprof-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvprof-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-sanitizer-api-10-2.\n",
            "Preparing to unpack .../09-cuda-sanitizer-api-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-sanitizer-api-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-memcheck-10-2.\n",
            "Preparing to unpack .../10-cuda-memcheck-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-memcheck-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cudart-10-2.\n",
            "Preparing to unpack .../11-cuda-cudart-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-10-2.\n",
            "Preparing to unpack .../12-cuda-driver-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-10-2.\n",
            "Preparing to unpack .../13-cuda-cudart-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cupti-10-2.\n",
            "Preparing to unpack .../14-cuda-cupti-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cupti-dev-10-2.\n",
            "Preparing to unpack .../15-cuda-cupti-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvtx-10-2.\n",
            "Preparing to unpack .../16-cuda-nvtx-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvtx-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-10-2.\n",
            "Preparing to unpack .../17-cuda-command-line-tools-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nsight-10-2.\n",
            "Preparing to unpack .../18-cuda-nsight-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvvp-10-2.\n",
            "Preparing to unpack .../19-cuda-nvvp-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvvp-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-10-2.\n",
            "Preparing to unpack .../20-cuda-nvrtc-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-10-2.\n",
            "Preparing to unpack .../21-cuda-nvrtc-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-10-2.\n",
            "Preparing to unpack .../22-cuda-cusolver-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-10-2.\n",
            "Preparing to unpack .../23-cuda-cusolver-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-10-2 (10.2.89-1) ...\n",
            "Preparing to unpack .../24-libcublas10_10.2.2.89-1_amd64.deb ...\n",
            "Unpacking libcublas10 (10.2.2.89-1) over (10.2.1.243-1) ...\n",
            "Preparing to unpack .../25-libcublas-dev_10.2.2.89-1_amd64.deb ...\n",
            "Unpacking libcublas-dev (10.2.2.89-1) over (10.2.1.243-1) ...\n",
            "Selecting previously unselected package cuda-cufft-10-2.\n",
            "Preparing to unpack .../26-cuda-cufft-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-10-2.\n",
            "Preparing to unpack .../27-cuda-cufft-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-curand-10-2.\n",
            "Preparing to unpack .../28-cuda-curand-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-curand-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-10-2.\n",
            "Preparing to unpack .../29-cuda-curand-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-10-2.\n",
            "Preparing to unpack .../30-cuda-cusparse-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-10-2.\n",
            "Preparing to unpack .../31-cuda-cusparse-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-npp-10-2.\n",
            "Preparing to unpack .../32-cuda-npp-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-npp-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-10-2.\n",
            "Preparing to unpack .../33-cuda-npp-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-10-2.\n",
            "Preparing to unpack .../34-cuda-nvml-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvjpeg-10-2.\n",
            "Preparing to unpack .../35-cuda-nvjpeg-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvjpeg-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvjpeg-dev-10-2.\n",
            "Preparing to unpack .../36-cuda-nvjpeg-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvjpeg-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nsight-compute-10-2.\n",
            "Preparing to unpack .../37-cuda-nsight-compute-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-compute-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nsight-systems-10-2.\n",
            "Preparing to unpack .../38-cuda-nsight-systems-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-systems-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-10-2.\n",
            "Preparing to unpack .../39-cuda-nvgraph-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-10-2.\n",
            "Preparing to unpack .../40-cuda-nvgraph-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-visual-tools-10-2.\n",
            "Preparing to unpack .../41-cuda-visual-tools-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-visual-tools-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-tools-10-2.\n",
            "Preparing to unpack .../42-cuda-tools-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-tools-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-samples-10-2.\n",
            "Preparing to unpack .../43-cuda-samples-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-samples-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-documentation-10-2.\n",
            "Preparing to unpack .../44-cuda-documentation-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-10-2.\n",
            "Preparing to unpack .../45-cuda-libraries-dev-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-libraries-10-2.\n",
            "Preparing to unpack .../46-cuda-libraries-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-toolkit-10-2.\n",
            "Preparing to unpack .../47-cuda-toolkit-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-toolkit-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-runtime-10-2.\n",
            "Preparing to unpack .../48-cuda-runtime-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-runtime-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-demo-suite-10-2.\n",
            "Preparing to unpack .../49-cuda-demo-suite-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-demo-suite-10-2 (10.2.89-1) ...\n",
            "Selecting previously unselected package cuda-10-2.\n",
            "Preparing to unpack .../50-cuda-10-2_10.2.89-1_amd64.deb ...\n",
            "Unpacking cuda-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-license-10-2 (10.2.89-1) ...\n",
            "*** LICENSE AGREEMENT ***\n",
            "By using this software you agree to fully comply with the terms and \n",
            "conditions of the EULA (End User License Agreement). The EULA is located\n",
            "at /usr/local/cuda-10.2/doc/EULA.txt. The EULA can also be found at\n",
            "http://docs.nvidia.com/cuda/eula/index.html. If you do not agree to the\n",
            "terms and conditions of the EULA, do not use the software.\n",
            "\n",
            "Setting up cuda-nvgraph-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvprune-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvrtc-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvtx-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvjpeg-10-2 (10.2.89-1) ...\n",
            "Setting up libcublas10 (10.2.2.89-1) ...\n",
            "Setting up libcublas-dev (10.2.2.89-1) ...\n",
            "Setting up cuda-cufft-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nsight-compute-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cusparse-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cuobjdump-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-sanitizer-api-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvjpeg-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cusolver-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-misc-headers-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvvp-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-curand-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cudart-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-npp-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cufft-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-libraries-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-memcheck-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvrtc-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-driver-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-npp-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nsight-systems-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nsight-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvdisasm-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvml-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvgraph-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvcc-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-nvprof-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cusparse-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-compiler-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-runtime-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-curand-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cusolver-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-demo-suite-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-gdb-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cudart-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-libraries-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-visual-tools-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-samples-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cupti-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-documentation-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-cupti-dev-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-command-line-tools-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-tools-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-toolkit-10-2 (10.2.89-1) ...\n",
            "Setting up cuda-10-2 (10.2.89-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBshyIE3SoXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "c04a65e1-c1ee-4bd6-fb56-812eb935d753"
      },
      "source": [
        "!ls -l /usr/local"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 72\n",
            "drwxr-xr-x  1 root root 4096 Jul  7 12:30 bin\n",
            "lrwxrwxrwx  1 root root    9 Jul  7 12:47 cuda -> cuda-10.2\n",
            "drwxr-xr-x 16 root root 4096 Jun 26 16:18 cuda-10.0\n",
            "drwxr-xr-x  1 root root 4096 Jun 26 16:20 cuda-10.1\n",
            "drwxr-xr-x 16 root root 4096 Jul  7 12:47 cuda-10.2\n",
            "drwxr-xr-x  1 root root 4096 Jun 26 16:27 etc\n",
            "drwxr-xr-x  2 root root 4096 Oct 29  2019 games\n",
            "drwxr-xr-x  2 root root 4096 Jun 26 16:38 _gcs_config_ops.so\n",
            "drwxr-xr-x  1 root root 4096 Jun 26 16:46 include\n",
            "drwxr-xr-x  1 root root 4096 Jun 26 16:47 lib\n",
            "-rw-r--r--  1 root root 1636 Jun 26 16:40 LICENSE.txt\n",
            "lrwxrwxrwx  1 root root    9 Oct 29  2019 man -> share/man\n",
            "drwxr-xr-x  2 root root 4096 Oct 29  2019 sbin\n",
            "-rw-r--r--  1 root root 7291 Jun 26 16:40 setup.cfg\n",
            "drwxr-xr-x  1 root root 4096 Jun 26 16:27 share\n",
            "drwxr-xr-x  2 root root 4096 Oct 29  2019 src\n",
            "drwxr-xr-x  2 root root 4096 Jun 26 16:48 xgboost\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeYBaElIVgUZ",
        "colab_type": "text"
      },
      "source": [
        "### Install TensorRT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTBy_RvnNx-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "a3ed289c-5ca9-453c-ba3c-cca14e8bb8ff"
      },
      "source": [
        "%%bash\n",
        "wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "\n",
        "dpkg -i nvidia-machine-learning-repo-*.deb\n",
        "apt-get update"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Reading database ... 144495 files and directories currently installed.)\n",
            "Preparing to unpack nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb ...\n",
            "Unpacking nvidia-machine-learning-repo-ubuntu1804 (1.0.0-1) over (1.0.0-1) ...\n",
            "Setting up nvidia-machine-learning-repo-ubuntu1804 (1.0.0-1) ...\n",
            "Hit:1 https://storage.googleapis.com/bazel-apt stable InRelease\n",
            "Ign:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:14 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Reading package lists...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-07-07 12:40:38--  https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2926 (2.9K) [application/x-deb]\n",
            "Saving to: ‘nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb.1’\n",
            "\n",
            "     0K ..                                                    100%  117M=0s\n",
            "\n",
            "2020-07-07 12:40:38 (117 MB/s) - ‘nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb.1’ saved [2926/2926]\n",
            "\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYqpXSMlOCJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbcd379a-f3d1-47c5-d9b4-f839e35c1545"
      },
      "source": [
        "%%bash\n",
        "version=\"6.0.1-1+cuda10.2\"\n",
        "sudo apt-get install libnvinfer6=${version} libnvonnxparsers6=${version} libnvparsers6=${version} libnvinfer-plugin6=${version} libnvinfer-dev=${version} libnvonnxparsers-dev=${version} libnvparsers-dev=${version} libnvinfer-plugin-dev=${version} python-libnvinfer=${version} python3-libnvinfer=${version}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following packages will be upgraded:\n",
            "  libnvinfer-dev libnvinfer-plugin-dev libnvinfer-plugin6 libnvinfer6\n",
            "  libnvonnxparsers-dev libnvonnxparsers6 libnvparsers-dev libnvparsers6\n",
            "  python-libnvinfer python3-libnvinfer\n",
            "10 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n",
            "Need to get 156 MB of archives.\n",
            "After this operation, 33.8 MB of additional disk space will be used.\n",
            "Get:1 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer-plugin-dev 6.0.1-1+cuda10.2 [1,874 kB]\n",
            "Get:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvonnxparsers-dev 6.0.1-1+cuda10.2 [166 kB]\n",
            "Get:3 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  python3-libnvinfer 6.0.1-1+cuda10.2 [370 kB]\n",
            "Get:4 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  python-libnvinfer 6.0.1-1+cuda10.2 [371 kB]\n",
            "Get:5 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvonnxparsers6 6.0.1-1+cuda10.2 [746 kB]\n",
            "Get:6 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer-plugin6 6.0.1-1+cuda10.2 [1,830 kB]\n",
            "Get:7 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvparsers-dev 6.0.1-1+cuda10.2 [536 kB]\n",
            "Get:8 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer-dev 6.0.1-1+cuda10.2 [75.4 MB]\n",
            "Get:9 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvparsers6 6.0.1-1+cuda10.2 [787 kB]\n",
            "Get:10 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer6 6.0.1-1+cuda10.2 [74.1 MB]\n",
            "Fetched 156 MB in 5s (34.4 MB/s)\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 156908 files and directories currently installed.)\r\n",
            "Preparing to unpack .../0-libnvinfer-plugin-dev_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking libnvinfer-plugin-dev (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Preparing to unpack .../1-libnvonnxparsers-dev_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking libnvonnxparsers-dev (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Preparing to unpack .../2-python3-libnvinfer_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking python3-libnvinfer (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Preparing to unpack .../3-python-libnvinfer_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking python-libnvinfer (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Preparing to unpack .../4-libnvonnxparsers6_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking libnvonnxparsers6 (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Preparing to unpack .../5-libnvinfer-plugin6_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking libnvinfer-plugin6 (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Preparing to unpack .../6-libnvparsers-dev_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking libnvparsers-dev (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Preparing to unpack .../7-libnvinfer-dev_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking libnvinfer-dev (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Preparing to unpack .../8-libnvparsers6_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking libnvparsers6 (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Preparing to unpack .../9-libnvinfer6_6.0.1-1+cuda10.2_amd64.deb ...\r\n",
            "Unpacking libnvinfer6 (6.0.1-1+cuda10.2) over (6.0.1-1+cuda10.0) ...\r\n",
            "Setting up libnvinfer6 (6.0.1-1+cuda10.2) ...\r\n",
            "Setting up libnvonnxparsers6 (6.0.1-1+cuda10.2) ...\r\n",
            "Setting up libnvinfer-plugin6 (6.0.1-1+cuda10.2) ...\r\n",
            "Setting up libnvparsers6 (6.0.1-1+cuda10.2) ...\r\n",
            "Setting up libnvinfer-dev (6.0.1-1+cuda10.2) ...\r\n",
            "Setting up python-libnvinfer (6.0.1-1+cuda10.2) ...\r\n",
            "Setting up libnvinfer-plugin-dev (6.0.1-1+cuda10.2) ...\r\n",
            "Setting up libnvparsers-dev (6.0.1-1+cuda10.2) ...\r\n",
            "Setting up python3-libnvinfer (6.0.1-1+cuda10.2) ...\r\n",
            "Setting up libnvonnxparsers-dev (6.0.1-1+cuda10.2) ...\r\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\r\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\r\n",
            "\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ezyr5ykVlp3",
        "colab_type": "text"
      },
      "source": [
        "Check the installed TensorRT version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jubMniGDNpT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "a60a9f9f-ab28-4377-ea94-6ed468c511b1"
      },
      "source": [
        "!dpkg -l | grep TensorRT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ii  libnvinfer-dev                          6.0.1-1+cuda10.2                                  amd64        TensorRT development libraries and headers\n",
            "ii  libnvinfer-plugin-dev                   6.0.1-1+cuda10.2                                  amd64        TensorRT plugin libraries\n",
            "ii  libnvinfer-plugin6                      6.0.1-1+cuda10.2                                  amd64        TensorRT plugin libraries\n",
            "ii  libnvinfer6                             6.0.1-1+cuda10.2                                  amd64        TensorRT runtime libraries\n",
            "ii  libnvonnxparsers-dev                    6.0.1-1+cuda10.2                                  amd64        TensorRT ONNX libraries\n",
            "ii  libnvonnxparsers6                       6.0.1-1+cuda10.2                                  amd64        TensorRT ONNX libraries\n",
            "ii  libnvparsers-dev                        6.0.1-1+cuda10.2                                  amd64        TensorRT parsers libraries\n",
            "ii  libnvparsers6                           6.0.1-1+cuda10.2                                  amd64        TensorRT parsers libraries\n",
            "ii  python-libnvinfer                       6.0.1-1+cuda10.2                                  amd64        Python bindings for TensorRT\n",
            "ii  python3-libnvinfer                      6.0.1-1+cuda10.2                                  amd64        Python 3 bindings for TensorRT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWIzQQv8VMdY",
        "colab_type": "text"
      },
      "source": [
        "### Install PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaXskzVtPufy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "acedd4ed-76bb-421a-ad0c-8d7a8606b978"
      },
      "source": [
        "#!pip install --upgrade --force-reinstall torch==1.5.0\n",
        "!pip install --upgrade --force-reinstall torch==1.5.1+cu101 torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.5.1+cu101 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2, 0.3.1, 0.4.0, 0.4.1, 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.4.0, 1.5.0, 1.5.1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch==1.5.1+cu101\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANwMhUNsgIW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ae5104d8-8b99-4c5e-ceaa-66685ccc1de0"
      },
      "source": [
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n",
        "print(torch.backends.cudnn.version())\n",
        "print(torch._C._cuda_getDriverVersion())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1\n",
            "10.2\n",
            "7605\n",
            "10010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpR4yIHEhCEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe8a4606-d077-4b07-d87e-aca17f97ed08"
      },
      "source": [
        "torch._C._cuda_isDriverSufficient()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbJNAAAzUdCl",
        "colab_type": "text"
      },
      "source": [
        "### Clone the repo and build TRTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk7HbPxgOyBd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3fd31510-2bf1-44b1-e190-e5ee5078300a"
      },
      "source": [
        "%%bash\n",
        "cd /content\n",
        "git clone https://github.com/vinhngx/TRTorch\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TRTorch'...\n",
            "bash: line 7: bazel: command not found\n",
            "bash: line 9: cd: /workspace/TRTorch/py: No such file or directory\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Ce9baySCp2",
        "colab_type": "text"
      },
      "source": [
        "Finally, we are ready to build and install TRTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaZbmilwQnLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "abec2607-abde-4f13-e1ce-152707343b52"
      },
      "source": [
        "%%bash\n",
        "cd /content/TRTorch\n",
        "cp notebooks/WORKSPACE .\n",
        "\n",
        "bazel build //:libtrtorch --compilation_mode opt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading: \n",
            "Loading: 0 packages loaded\n",
            "Analyzing: target //:libtrtorch (0 packages loaded, 0 targets configured)\n",
            "INFO: Analyzed target //:libtrtorch (5 packages loaded, 2323 targets configured).\n",
            "\n",
            "INFO: Found 1 target...\n",
            "[0 / 9] [Prepa] BazelWorkspaceStatusAction stable-status.txt\n",
            "[260 / 516] [Prepa] Symlinking virtual headers for @libtorch//:c10\n",
            "[449 / 516] checking cached actions\n",
            "[449 / 516] [Prepa] action 'SolibSymlink _solib_k8/_U@tensorrt_S_S_Cnvinfer_Ulib___Uexternal_Stensorrt_Slib_Sx86_U64-linux-gnu/libnvinfer.so'\n",
            "[452 / 516] checking cached actions\n",
            "[452 / 516] [Prepa] action 'SolibSymlink _solib_k8/_U@cudnn_S_S_Ccudnn_Ulib___Uexternal_Scudnn_Slib_Sx86_U64-linux-gnu/libcudnn.so.7.6.5'\n",
            "[454 / 516] Compiling cpp/api/src/extra_info.cpp; 6s processwrapper-sandbox\n",
            "[455 / 516] Compiling core/conversion/conversion.cpp; 3s processwrapper-sandbox ... (2 actions, 1 running)\n",
            "[456 / 516] Compiling core/conversion/conversion.cpp; 11s processwrapper-sandbox ... (2 actions running)\n",
            "[457 / 516] Compiling core/conversion/converters/impl/conv_deconv.cpp; 12s processwrapper-sandbox ... (2 actions running)\n",
            "[458 / 516] Compiling core/conversion/converters/impl/conv_deconv.cpp; 23s processwrapper-sandbox ... (2 actions running)\n",
            "[460 / 516] Compiling core/conversion/converters/impl/activation.cpp; 6s processwrapper-sandbox ... (2 actions running)\n",
            "[462 / 516] Compiling cpp/api/src/trtorch.cpp; 8s processwrapper-sandbox ... (2 actions running)\n",
            "[463 / 516] Compiling core/execution/register_trt_op.cpp; 23s processwrapper-sandbox ... (2 actions running)\n",
            "[467 / 516] Compiling core/compiler.cpp; 11s processwrapper-sandbox ... (2 actions running)\n",
            "[470 / 516] Compiling core/conversion/converters/impl/select.cpp; 16s processwrapper-sandbox ... (2 actions running)\n",
            "[473 / 516] Compiling core/lowering/lowering.cpp; 10s processwrapper-sandbox ... (2 actions running)\n",
            "[477 / 516] Compiling core/conversion/converters/impl/stack.cpp; 26s processwrapper-sandbox ... (2 actions running)\n",
            "[479 / 516] Compiling core/conversion/evaluators/aten.cpp; 31s processwrapper-sandbox ... (2 actions running)\n",
            "[484 / 516] Compiling core/lowering/passes/unpack_log_softmax.cpp; 8s processwrapper-sandbox ... (2 actions running)\n",
            "[491 / 516] Compiling core/conversion/converters/impl/plugins/interpolate_plugin.cpp; 9s processwrapper-sandbox ... (2 actions running)\n",
            "[495 / 516] Compiling cpp/api/src/ptq.cpp; 12s processwrapper-sandbox ... (2 actions running)\n",
            "[504 / 516] Compiling core/conversion/converters/impl/concat.cpp; 6s processwrapper-sandbox ... (2 actions running)\n",
            "[517 / 575] Compiling core/lowering/passes/unpack_addmm.cpp; 11s processwrapper-sandbox ... (2 actions running)\n",
            "[527 / 575] Compiling core/execution/register_trt_op.cpp; 14s processwrapper-sandbox ... (2 actions running)\n",
            "[535 / 575] Compiling core/conversion/converters/impl/plugins/interpolate_plugin.cpp; 30s processwrapper-sandbox ... (2 actions running)\n",
            "[547 / 575] Compiling core/conversion/converters/impl/conv_deconv.cpp; 24s processwrapper-sandbox ... (2 actions running)\n",
            "[1,057 / 1,061] Compiling cpp/trtorchc/main.cpp; 13s processwrapper-sandbox\n",
            "Target //:libtrtorch up-to-date:\n",
            "  bazel-bin/libtrtorch.tar.gz\n",
            "INFO: Elapsed time: 954.459s, Critical Path: 36.05s\n",
            "INFO: 123 processes: 123 processwrapper-sandbox.\n",
            "INFO: Build completed successfully, 1061 total actions\n",
            "INFO: Build completed successfully, 1061 total actions\n",
            "bash: line 6: cd: /workspace/TRTorch/py: No such file or directory\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkzFtgyFYB6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "caff37b5-2bda-4da4-9666-5abf20f533e6"
      },
      "source": [
        "%%bash\n",
        "cd /content/TRTorch/py\n",
        "python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "running install\n",
            "building libtrtorch\n",
            "creating version file\n",
            "copying library into module\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "creating build/lib.linux-x86_64-3.6/trtorch\n",
            "copying trtorch/_version.py -> build/lib.linux-x86_64-3.6/trtorch\n",
            "copying trtorch/logging.py -> build/lib.linux-x86_64-3.6/trtorch\n",
            "copying trtorch/_extra_info.py -> build/lib.linux-x86_64-3.6/trtorch\n",
            "copying trtorch/__init__.py -> build/lib.linux-x86_64-3.6/trtorch\n",
            "copying trtorch/_types.py -> build/lib.linux-x86_64-3.6/trtorch\n",
            "copying trtorch/_compiler.py -> build/lib.linux-x86_64-3.6/trtorch\n",
            "running egg_info\n",
            "creating trtorch.egg-info\n",
            "writing trtorch.egg-info/PKG-INFO\n",
            "writing dependency_links to trtorch.egg-info/dependency_links.txt\n",
            "writing requirements to trtorch.egg-info/requires.txt\n",
            "writing top-level names to trtorch.egg-info/top_level.txt\n",
            "writing manifest file 'trtorch.egg-info/SOURCES.txt'\n",
            "writing manifest file 'trtorch.egg-info/SOURCES.txt'\n",
            "creating build/lib.linux-x86_64-3.6/trtorch/lib\n",
            "copying trtorch/lib/libtrtorch.so -> build/lib.linux-x86_64-3.6/trtorch/lib\n",
            "running build_ext\n",
            "building 'trtorch._C' extension\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/trtorch\n",
            "creating build/temp.linux-x86_64-3.6/trtorch/csrc\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -UNDEBUG -I/content/TRTorch/py/../ -I/content/TRTorch/py/../bazel-TRTorch/external/tensorrt/include -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c trtorch/csrc/trtorch_py.cpp -o build/temp.linux-x86_64-3.6/trtorch/csrc/trtorch_py.o -D_GLIBCXX_USE_CXX11_ABI=0 -Wno-deprecated-declaration -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/trtorch/csrc/trtorch_py.o -L/content/TRTorch/py/trtorch/lib/libtrtorch.so -L/content/TRTorch/py/trtorch/lib/ -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda/lib64 -ltrtorch -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/trtorch/_C.cpython-36m-x86_64-linux-gnu.so -D_GLIBCXX_USE_CXX11_ABI=0-Wl,--no-as-needed -ltrtorch -Wl,-rpath,$ORIGIN/lib\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/dist-packages/trtorch\n",
            "copying build/lib.linux-x86_64-3.6/trtorch/_version.py -> /usr/local/lib/python3.6/dist-packages/trtorch\n",
            "copying build/lib.linux-x86_64-3.6/trtorch/logging.py -> /usr/local/lib/python3.6/dist-packages/trtorch\n",
            "copying build/lib.linux-x86_64-3.6/trtorch/_extra_info.py -> /usr/local/lib/python3.6/dist-packages/trtorch\n",
            "copying build/lib.linux-x86_64-3.6/trtorch/__init__.py -> /usr/local/lib/python3.6/dist-packages/trtorch\n",
            "creating /usr/local/lib/python3.6/dist-packages/trtorch/lib\n",
            "copying build/lib.linux-x86_64-3.6/trtorch/lib/libtrtorch.so -> /usr/local/lib/python3.6/dist-packages/trtorch/lib\n",
            "copying build/lib.linux-x86_64-3.6/trtorch/_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages/trtorch\n",
            "copying build/lib.linux-x86_64-3.6/trtorch/_types.py -> /usr/local/lib/python3.6/dist-packages/trtorch\n",
            "copying build/lib.linux-x86_64-3.6/trtorch/_compiler.py -> /usr/local/lib/python3.6/dist-packages/trtorch\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/trtorch/_version.py to _version.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/trtorch/logging.py to logging.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/trtorch/_extra_info.py to _extra_info.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/trtorch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/trtorch/_types.py to _types.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/dist-packages/trtorch/_compiler.py to _compiler.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Copying trtorch.egg-info to /usr/local/lib/python3.6/dist-packages/trtorch-0.0.2-py3.6.egg-info\n",
            "running install_scripts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading: \n",
            "Loading: 0 packages loaded\n",
            "INFO: Build options --cxxopt, --define, and --linkopt have changed, discarding analysis cache.\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 0 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "Analyzing: target //cpp/api/lib:libtrtorch.so (0 packages loaded, 62 targets configured)\n",
            "INFO: Analyzed target //cpp/api/lib:libtrtorch.so (1 packages loaded, 1952 targets configured).\n",
            "INFO: Found 1 target...\n",
            "[0 / 1] [Prepa] BazelWorkspaceStatusAction stable-status.txt\n",
            "[455 / 509] Compiling cpp/api/src/extra_info.cpp; 2s processwrapper-sandbox ... (2 actions, 1 running)\n",
            "[456 / 509] Compiling core/execution/register_trt_op.cpp; 10s processwrapper-sandbox ... (2 actions, 1 running)\n",
            "[457 / 509] Compiling core/execution/register_trt_op.cpp; 21s processwrapper-sandbox ... (2 actions running)\n",
            "[459 / 509] Compiling core/lowering/passes/fuse_addmm_branches.cpp; 2s processwrapper-sandbox ... (2 actions running)\n",
            "[461 / 509] Compiling core/lowering/lowering.cpp; 3s processwrapper-sandbox ... (2 actions running)\n",
            "[463 / 509] Compiling core/conversion/tensorcontainer/TensorContainer.cpp; 5s processwrapper-sandbox ... (2 actions running)\n",
            "[467 / 509] Compiling core/conversion/evaluators/aten.cpp; 2s processwrapper-sandbox ... (2 actions running)\n",
            "[468 / 509] Compiling core/conversion/evaluators/aten.cpp; 23s processwrapper-sandbox ... (2 actions running)\n",
            "[471 / 509] Compiling core/conversion/conversion.cpp; 12s processwrapper-sandbox ... (2 actions running)\n",
            "[474 / 509] Compiling core/compiler.cpp; 10s processwrapper-sandbox ... (2 actions running)\n",
            "[478 / 509] Compiling core/lowering/passes/unpack_batch_norm.cpp; 7s processwrapper-sandbox\n",
            "[481 / 509] Compiling core/conversion/converters/impl/element_wise.cpp; 7s processwrapper-sandbox ... (2 actions running)\n",
            "[486 / 509] Compiling core/conversion/converters/impl/select.cpp; 16s processwrapper-sandbox ... (2 actions running)\n",
            "[492 / 509] Compiling core/conversion/converters/impl/shuffle.cpp; 1s processwrapper-sandbox ... (2 actions running)\n",
            "[497 / 509] Compiling core/execution/TRTEngine.cpp; 12s processwrapper-sandbox ... (2 actions running)\n",
            "[507 / 509] Compiling core/conversion/converters/impl/pooling.cpp; 20s processwrapper-sandbox\n",
            "Target //cpp/api/lib:libtrtorch.so up-to-date:\n",
            "  bazel-bin/cpp/api/lib/libtrtorch.so\n",
            "INFO: Elapsed time: 503.073s, Critical Path: 35.89s\n",
            "INFO: 52 processes: 52 processwrapper-sandbox.\n",
            "INFO: Build completed successfully, 502 total actions\n",
            "INFO: Build completed successfully, 502 total actions\n",
            "/usr/lib/python3.6/distutils/dist.py:261: UserWarning: Unknown distribution option: 'platform'\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:304: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri5D_BzPMMFg",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"2\"></a>\n",
        "## 2. Creating TorchScript modules\n",
        "\n",
        "Here we create two submodules for a feature extractor and a classifier and stitch them together in a single LeNet module. In this case this is overkill but modules give us granular control over our program including where we decide to optimize and where we don't. It is also the unit that the TorchScript compiler operates on. So you can decide to only convert/optimize the feature extractor and leave the classifier in standard PyTorch or you can convert the whole thing. When compiling your module to TorchScript, there are two paths: Tracing and Scripting.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdn_6mSDMMFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNetFeatExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetFeatExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        return x\n",
        "\n",
        "class LeNetClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x,1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.feat = LeNetFeatExtractor()\n",
        "        self.classifer = LeNetClassifier()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feat(x)\n",
        "        x = self.classifer(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Wd-XcLMMFq",
        "colab_type": "text"
      },
      "source": [
        "Let us define a helper function to benchmark a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HZt53EnMMFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def benchmark(model, input_shape=(1024, 1, 32, 32), dtype='fp32', nwarmup=50, nruns=10000):\n",
        "    input_data = torch.randn(input_shape)\n",
        "    input_data = input_data.to(\"cuda\")\n",
        "    if dtype=='fp16':\n",
        "        input_data = input_data.half()\n",
        "        \n",
        "    for _ in range(nwarmup):\n",
        "        results = model(input_data)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    time_arr = []\n",
        "    for _ in range(1, nruns+1):\n",
        "        start_time = time.time()\n",
        "        results = model(input_data)\n",
        "        time_arr.append(time.time() - start_time)\n",
        "        \n",
        "        if _%1000==0:\n",
        "            print('Iteration %d, ave batch time %.2f ms'%(_, np.mean(time_arr)*1000))\n",
        "     \n",
        "    print('Average batch time: %.2f ms'%(np.mean(time_arr)*1000))       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZb4WN5xMMF0",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjuGcY7BMMF2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "9ea774d3-e857-482d-b92b-b4c72715470f"
      },
      "source": [
        "model = LeNet()\n",
        "model.to(\"cuda\").eval()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3e591b34a4de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mAlternatively\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m \u001b[0mto\u001b[0m \u001b[0minstall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0myour\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m of the CUDA driver.\"\"\".format(str(torch._C._cuda_getDriverVersion())))\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nThe NVIDIA driver on your system is too old (found version 10010).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: https://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxrA-x5HMMGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "1191ca40-517c-4d48-a58c-bcbf7d14e42e"
      },
      "source": [
        "benchmark(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e2f963dfc125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-867d7eb909a1>\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(model, input_shape, dtype, nwarmup, nruns)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fp32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnwarmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnruns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'fp16'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mAlternatively\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m \u001b[0mto\u001b[0m \u001b[0minstall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0myour\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m of the CUDA driver.\"\"\".format(str(torch._C._cuda_getDriverVersion())))\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nThe NVIDIA driver on your system is too old (found version 10010).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: https://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTlLpzSuMMGL",
        "colab_type": "text"
      },
      "source": [
        "### Tracing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrMQOcGxMMGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traced_model = torch.jit.trace(model, torch.empty([1,1,32,32]).to(\"cuda\"))\n",
        "traced_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSSW2qqlMMGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark(traced_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3d8EeswMMGa",
        "colab_type": "text"
      },
      "source": [
        "### Scripting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWFC4DIvMMGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LeNet().to(\"cuda\").eval()\n",
        "script_model = torch.jit.script(model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRL1aFeYMMGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "script_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4H1HbKmMMGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark(script_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdPv7DL-MMGw",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"3\"></a>\n",
        "## 3. Compiling with TRTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odnuXRq-MMGx",
        "colab_type": "text"
      },
      "source": [
        "### TorchScript traced model\n",
        "\n",
        "First, we compile the TorchScript traced model with TRTorch. Notice the performance impact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_7fImsDMMGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import trtorch\n",
        "\n",
        "compile_settings = {\n",
        "    \"input_shapes\": [\n",
        "        {\n",
        "            \"min\" : [1, 1, 32, 32],\n",
        "            \"opt\" : [1, 1, 33, 33],\n",
        "            \"max\" : [1, 1, 34, 34],\n",
        "        }\n",
        "    ],\n",
        "    \"op_precision\": torch.half # Run with FP16\n",
        "}\n",
        "\n",
        "trt_ts_module = trtorch.compile(traced_model, compile_settings)\n",
        "\n",
        "input_data = torch.randn((1, 1, 32, 32))\n",
        "input_data = input_data.half().to(\"cuda\")\n",
        "\n",
        "input_data = input_data.half()\n",
        "result = trt_ts_module(input_data)\n",
        "torch.jit.save(trt_ts_module, \"trt_ts_module.ts\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTj3nJWRMMG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark(trt_ts_module, dtype=\"fp16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G7_IT3MMHC",
        "colab_type": "text"
      },
      "source": [
        "### TorchScript script model\n",
        "\n",
        "Next, we compile the TorchScript script model with TRTorch. Notice the performance impact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAuzvNQAMMHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import trtorch\n",
        "\n",
        "compile_settings = {\n",
        "    \"input_shapes\": [\n",
        "        {\n",
        "            \"min\" : [1, 1, 32, 32],\n",
        "            \"opt\" : [1, 1, 33, 33],\n",
        "            \"max\" : [1, 1, 34, 34],\n",
        "        }\n",
        "    ],\n",
        "    \"op_precision\": torch.half # Run with FP16\n",
        "}\n",
        "\n",
        "trt_script_module = trtorch.compile(script_model, compile_settings)\n",
        "\n",
        "input_data = torch.randn((1, 1, 32, 32))\n",
        "input_data = input_data.half().to(\"cuda\")\n",
        "\n",
        "input_data = input_data.half()\n",
        "result = trt_script_module(input_data)\n",
        "torch.jit.save(trt_script_module, \"trt_script_module.ts\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZxvhBsuMMHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benchmark(trt_ts_module, dtype=\"fp16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-84RaVx5MMHP",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this notebook, we have walked through the complete process of compiling TorchScript models with TRTorch and test the performance impact of the optimization.\n",
        "\n",
        "## What's next\n",
        "Now it's time to try TRTorch on your own model. Fill out issues at https://github.com/NVIDIA/TRTorch. Your involvement will help future development of TRTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLvqftAsMMHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}